from typing import AsyncGenerator
import re

from dailyai.pipeline.frames import TextFrame, Frame
from dailyai.pipeline.frame_processor import FrameProcessor
from dailyai.pipeline.frames import (
    Frame,
    TextFrame,
    LLMResponseEndFrame,
    AudioFrame,
    ImageFrame,
    UserStoppedSpeakingFrame,
)


class StoryStartFrame(TextFrame):
    pass


class StoryPageFrame(TextFrame):
    pass


class StoryPromptFrame(TextFrame):
    pass


class StoryProcessor(FrameProcessor):
    def __init__(self, messages, story):
        self._messages = messages
        self._text = ""
        self._story = story

    async def process_frame(self, frame: Frame) -> AsyncGenerator[Frame, None]:
        """
        The response from the LLM service looks like:
        A comment about the user's choice
        [start] (when the cat starts telling parts of the story)
        A sentence of the story
        [break] (between each sentence/'page' of the story)
        [prompt] (when the cat asks the user to make a decision)
        Question about the next part of the story

        1. Catch the frames that are generated by the LLM service
        """
        if isinstance(frame, UserStoppedSpeakingFrame):
            # yield ImageFrame(None, images["grandma-writing.png"])
            yield UserStoppedSpeakingFrame()
            # yield AudioFrame()

        elif isinstance(frame, TextFrame):
            self._text += frame.text

            if re.findall(r".*\[[sS]tart\].*", self._text):
                # Then we have the intro. Send it to speech ASAP
                self._text = self._text.replace("[Start]", "")
                self._text = self._text.replace("[start]", "")

                self._text = self._text.replace("\n", " ")
                if len(self._text) > 2:
                    # yield ImageFrame(None, images["grandma-writing.png"])
                    yield StoryStartFrame(self._text)
                    # yield AudioFrame(sounds["ding3.wav"])
                self._text = ""

            elif re.findall(r".*\[[bB]reak\].*", self._text):
                # Then it's a page of the story. Get an image too
                self._text = self._text.replace("[Break]", "")
                self._text = self._text.replace("[break]", "")
                self._text = self._text.replace("\n", " ")
                if len(self._text) > 2:
                    self._story.append(self._text)
                    yield StoryPageFrame(self._text)
                    # yield AudioFrame(sounds["ding3.wav"])

                self._text = ""
            elif re.findall(r".*\[[pP]rompt\].*", self._text):
                # Then it's question time. Flush any
                # text here as a story page, then set
                # the var to get to prompt mode
                # cb: trying scene now
                # self.handle_chunk(self._text)
                self._text = self._text.replace("[Prompt]", "")
                self._text = self._text.replace("[prompt]", "")

                self._text = self._text.replace("\n", " ")
                if len(self._text) > 2:
                    self._story.append(self._text)
                    yield StoryPageFrame(self._text)
            else:
                # After the prompt thing, we'll catch an LLM end to get the
                # last bit
                pass
        elif isinstance(frame, LLMResponseEndFrame):
            # yield ImageFrame(None, images["grandma-writing.png"])
            yield StoryPromptFrame(self._text)
            self._text = ""
            yield frame
            # yield ImageFrame(None, images["grandma-listening.png"])
            # yield AudioFrame(sounds["listening.wav"])

        else:
            # pass through everything that's not a TextFrame
            yield frame
